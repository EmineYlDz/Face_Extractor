{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## **Reading the Dataset**\n","\n","We're reading the folders and splitting them into **train and test set** for training purposes."]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2023-03-04T15:08:51.350553Z","iopub.status.busy":"2023-03-04T15:08:51.350074Z","iopub.status.idle":"2023-03-04T15:08:51.359348Z","shell.execute_reply":"2023-03-04T15:08:51.357927Z","shell.execute_reply.started":"2023-03-04T15:08:51.350508Z"},"trusted":true},"outputs":[{"data":{"text/plain":["('2.12.0', '1.23.5')"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import os\n","import cv2\n","import random\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from keras.applications.resnet import preprocess_input\n","import tensorflow as tf\n","tf.__version__, np.__version__"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2023-03-04T15:28:51.808233Z","iopub.status.busy":"2023-03-04T15:28:51.807762Z","iopub.status.idle":"2023-03-04T15:28:51.825206Z","shell.execute_reply":"2023-03-04T15:28:51.823766Z","shell.execute_reply.started":"2023-03-04T15:28:51.808194Z"},"trusted":true},"outputs":[],"source":["path = '../Dataset_Siamese2'\n","list_dirs = os.listdir(path)\n","\n","def create_generator_dataset(list_dirs, maxfiles = 20):\n","    list_path_images = []\n","    for dir in list_dirs:\n","        new_path = os.path.join(path, dir)\n","        images = os.listdir(new_path)[:maxfiles]\n","        num_images = len(images)\n","        if num_images >= 2:\n","            for i in range(num_images - 1):\n","                for j in range(i +1, num_images):\n","\n","                    anchor = os.path.join(new_path, images[i])\n","                    positive = os.path.join(new_path, images[j])\n","\n","                    count = 0\n","                    while count < 1:\n","                        negative_dir = dir\n","                        while negative_dir == dir:\n","                            negative_dir = random.choice(list_dirs)\n","\n","                        negative_images = os.listdir(f'{path}/{negative_dir}')\n","                        negative_image = random.choice(negative_images)\n","                        negative_dir = os.path.join(path, negative_dir)\n","                        negative = os.path.join(negative_dir, negative_image)\n","                        count +=1\n","\n","                        list_path_images.append([positive, anchor, negative])\n","\n","    random.shuffle(list_path_images)\n","    return list_path_images"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2023-03-04T15:28:54.611762Z","iopub.status.busy":"2023-03-04T15:28:54.611347Z","iopub.status.idle":"2023-03-04T15:29:11.418055Z","shell.execute_reply":"2023-03-04T15:29:11.416835Z","shell.execute_reply.started":"2023-03-04T15:28:54.611725Z"},"trusted":true},"outputs":[],"source":["triplet_dataset = create_generator_dataset(list_dirs)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Creating Triplets\n","\n","We use the train and test list to create triplets of **(anchor, postive, negative)** face data, where positive is the same person and negative is a different person than anchor."]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2023-03-04T15:11:30.687827Z","iopub.status.busy":"2023-03-04T15:11:30.687414Z","iopub.status.idle":"2023-03-04T15:11:30.695528Z","shell.execute_reply":"2023-03-04T15:11:30.694101Z","shell.execute_reply.started":"2023-03-04T15:11:30.687762Z"},"trusted":true},"outputs":[],"source":["def process_image(path):\n","    img = cv2.imread(path)\n","    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","    return img\n","\n","def split_data(list_file, ratio):\n","    if ratio[0] + ratio[1] + ratio[2] != 1:\n","        print('total ratio must equal 1')\n","        return\n","    else:\n","        train = int(len(list_file)* ratio[0])\n","        val = int(len(list_file)* ratio[1])\n","\n","    return list_file[:train], list_file[train: (train + val)], list_file[(train + val):]"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2023-03-04T15:29:14.873757Z","iopub.status.busy":"2023-03-04T15:29:14.873362Z","iopub.status.idle":"2023-03-04T15:29:14.892467Z","shell.execute_reply":"2023-03-04T15:29:14.891071Z","shell.execute_reply.started":"2023-03-04T15:29:14.873722Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["2463\n","307\n","309\n"]}],"source":["train, val, test = split_data(triplet_dataset, [0.8, 0.1, 0.1])\n","print(len(train))\n","print(len(val))\n","print(len(test))"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Creating Batch-Generator\n","\n","Creating a **Batch-Generator** that converts the triplets passed into batches of face-data and **preproccesses** it before returning the data into seperate lists.\n","\n","**Parameters:**\n","- Batch_size: Batch_size of the data to return\n","- Preprocess: Whether to preprocess the data or not"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2023-03-04T15:29:42.949294Z","iopub.status.busy":"2023-03-04T15:29:42.948880Z","iopub.status.idle":"2023-03-04T15:29:42.958254Z","shell.execute_reply":"2023-03-04T15:29:42.956932Z","shell.execute_reply.started":"2023-03-04T15:29:42.949259Z"},"trusted":true},"outputs":[],"source":["def generate_batch_dataset(list_files, batch_size = 64, preprocess = True):\n","    num_batch = len(list_files)// batch_size\n","\n","    for i in range(num_batch + 1):\n","        anchor = []\n","        positive = []\n","        negative = []\n","        j = i*batch_size\n","\n","        while j < (i+1) * batch_size and j < len(list_files):\n","            a, p, n = list_files[j]\n","\n","            anchor.append(process_image(a))\n","            positive.append(process_image(p))\n","            negative.append(process_image(n))\n","\n","            j+=1\n","        anchor = np.array(anchor)\n","        positive = np.array(positive)\n","        negative = np.array(negative)\n","    \n","        if preprocess:\n","            anchor = preprocess_input(anchor)\n","            positive = preprocess_input(positive)\n","            negative = preprocess_input(negative)\n","    \n","        yield ([positive, anchor, negative])"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2023-03-04T15:29:48.785130Z","iopub.status.busy":"2023-03-04T15:29:48.784687Z","iopub.status.idle":"2023-03-04T15:29:48.790625Z","shell.execute_reply":"2023-03-04T15:29:48.789331Z","shell.execute_reply.started":"2023-03-04T15:29:48.785093Z"},"trusted":true},"outputs":[],"source":["train_generator = generate_batch_dataset(train, batch_size = 128)\n","val_generator = generate_batch_dataset(val, batch_size = 128)\n","test_generator = generate_batch_dataset(test, batch_size = 16)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Plotting the Data\n","\n","Plotting the data generated from **get_batch()** to see the results"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["num_plots = 6\n","\n","f, axes = plt.subplots(num_plots, 3, figsize=(15, 20))\n","\n","for x in train_generator:\n","    a,p,n = x\n","    for i in range(num_plots):\n","        axes[i, 0].imshow(a[i])\n","        axes[i, 1].imshow(p[i])\n","        axes[i, 2].imshow(n[i])\n","        i+=1\n","        break\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["CREATE THE MODEL"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2023-03-04T15:14:32.256376Z","iopub.status.busy":"2023-03-04T15:14:32.255954Z","iopub.status.idle":"2023-03-04T15:14:32.262701Z","shell.execute_reply":"2023-03-04T15:14:32.261408Z","shell.execute_reply.started":"2023-03-04T15:14:32.256338Z"},"trusted":true},"outputs":[],"source":["from keras.applications.resnet import ResNet50\n","from keras.applications.xception import Xception\n","from keras.layers import Dense, Flatten, Lambda, Input, BatchNormalization, Conv2D, MaxPool2D, Dropout\n","from keras.models import Model, Sequential\n","import tensorflow as tf\n","from keras import backend, layers, metrics\n"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-03-04T15:12:01.738934Z","iopub.status.busy":"2023-03-04T15:12:01.738453Z","iopub.status.idle":"2023-03-04T15:12:01.746386Z","shell.execute_reply":"2023-03-04T15:12:01.744803Z","shell.execute_reply.started":"2023-03-04T15:12:01.738883Z"},"trusted":true},"outputs":[],"source":["class Distance(tf.keras.layers.Layer):\n","    def __init__(self, **kwarg):\n","        super().__init__(**kwarg)\n","\n","    def call(self,anchor, positive, negative):\n","        d_pos = tf.reduce_sum(tf.square(positive - anchor), -1)\n","        d_neg = tf.reduce_sum(tf.square(negative - anchor), -1)\n","        return (d_pos, d_neg)\n","\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-03-04T15:12:05.255239Z","iopub.status.busy":"2023-03-04T15:12:05.254759Z","iopub.status.idle":"2023-03-04T15:12:05.263381Z","shell.execute_reply":"2023-03-04T15:12:05.261755Z","shell.execute_reply.started":"2023-03-04T15:12:05.255200Z"},"trusted":true},"outputs":[],"source":["def encoder(input_shape):\n","    base_cnn = ResNet50(\n","        weights=\"imagenet\", input_shape= input_shape, include_top=False, pooling='avg',\n","    )\n","    trainable = False\n","    for layer in base_cnn.layers:\n","        if layer.name == \"conv5_block1_out\":\n","            trainable = True\n","        layer.trainable = trainable\n","        \n","    encode_model = Sequential([\n","    base_cnn,\n","    Dense(256, activation = 'relu'),\n","    BatchNormalization(),\n","    Dense(128, activation = 'relu'),\n","    Lambda(lambda x: tf.math.l2_normalize(x, axis = 1))\n","  ])\n","    \n","    return encode_model"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2023-03-04T15:12:10.726446Z","iopub.status.busy":"2023-03-04T15:12:10.726050Z","iopub.status.idle":"2023-03-04T15:12:10.733281Z","shell.execute_reply":"2023-03-04T15:12:10.731838Z","shell.execute_reply.started":"2023-03-04T15:12:10.726411Z"},"trusted":true},"outputs":[],"source":["def final_model(input_shape = (150, 125, 3) ):\n","    \n","    encode = encoder(input_shape)\n","\n","    input_a = Input(input_shape, name = 'input_anchor')\n","    input_p = Input(input_shape, name = 'input_positive')\n","    input_n = Input(input_shape, name = 'input_negative')\n","\n","    feature_a = encode(input_a)\n","    feature_p = encode(input_p)\n","    feature_n = encode(input_n)\n","\n","    distances = Distance()(\n","      feature_a,\n","      feature_p,\n","      feature_n\n","    )\n","\n","    model = Model(inputs = [input_a, input_p, input_n], outputs = distances)\n","    return model"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-03-04T15:13:25.755976Z","iopub.status.busy":"2023-03-04T15:13:25.755487Z","iopub.status.idle":"2023-03-04T15:13:30.161367Z","shell.execute_reply":"2023-03-04T15:13:30.160081Z","shell.execute_reply.started":"2023-03-04T15:13:25.755926Z"},"trusted":true},"outputs":[],"source":["siamese_network = final_model()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-04T15:13:31.154258Z","iopub.status.busy":"2023-03-04T15:13:31.153808Z","iopub.status.idle":"2023-03-04T15:13:31.370400Z","shell.execute_reply":"2023-03-04T15:13:31.368940Z","shell.execute_reply.started":"2023-03-04T15:13:31.154219Z"},"trusted":true},"outputs":[],"source":["tf.keras.utils.plot_model(siamese_network, show_shapes=True, show_layer_names=True)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-03-04T15:13:41.829124Z","iopub.status.busy":"2023-03-04T15:13:41.828680Z","iopub.status.idle":"2023-03-04T15:13:41.840422Z","shell.execute_reply":"2023-03-04T15:13:41.838567Z","shell.execute_reply.started":"2023-03-04T15:13:41.829085Z"},"trusted":true},"outputs":[],"source":["class SiameseModel(Model):\n","    # Builds a Siamese model based on a base-model\n","    def __init__(self, siamese_network, margin=1.0):\n","        super(SiameseModel, self).__init__()\n","        \n","        self.margin = margin\n","        self.siamese_network = siamese_network\n","        self.loss_tracker = metrics.Mean(name=\"loss\")\n","\n","    def call(self, inputs):\n","        return self.siamese_network(inputs)\n","\n","    def train_step(self, data):\n","        # GradientTape get the gradients when we compute loss, and uses them to update the weights\n","        with tf.GradientTape() as tape:\n","            loss = self._compute_loss(data)\n","            \n","        gradients = tape.gradient(loss, self.siamese_network.trainable_weights)\n","        self.optimizer.apply_gradients(zip(gradients, self.siamese_network.trainable_weights))\n","        \n","        self.loss_tracker.update_state(loss)\n","        return {\"loss\": self.loss_tracker.result()}\n","\n","    def test_step(self, data):\n","        loss = self._compute_loss(data)\n","        \n","        self.loss_tracker.update_state(loss)\n","        return {\"loss\": self.loss_tracker.result()}\n","\n","    def _compute_loss(self, data):\n","        # Get the two distances from the network, then compute the triplet loss\n","        ap_distance, an_distance = self.siamese_network(data)\n","        loss = tf.maximum(ap_distance - an_distance + self.margin, 0.0)\n","        return loss\n","\n","    @property\n","    def metrics(self):\n","        # We need to list our metrics so the reset_states() can be called automatically.\n","        return [self.loss_tracker]"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-03-04T15:14:48.629945Z","iopub.status.busy":"2023-03-04T15:14:48.629485Z","iopub.status.idle":"2023-03-04T15:14:48.664699Z","shell.execute_reply":"2023-03-04T15:14:48.663531Z","shell.execute_reply.started":"2023-03-04T15:14:48.629901Z"},"trusted":true},"outputs":[],"source":["siamese_model = SiameseModel(siamese_network)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=1e-3, epsilon=1e-01)\n","siamese_model.compile(optimizer=optimizer)"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2023-03-04T15:16:14.062194Z","iopub.status.busy":"2023-03-04T15:16:14.061746Z","iopub.status.idle":"2023-03-04T15:16:14.070360Z","shell.execute_reply":"2023-03-04T15:16:14.069152Z","shell.execute_reply.started":"2023-03-04T15:16:14.062154Z"},"trusted":true},"outputs":[],"source":["def test_on_triplets(batch_size = 256):\n","    pos_scores, neg_scores = [], []\n","\n","    for data in generate_batch_dataset(val, batch_size = 128):\n","        prediction = siamese_model.predict(data)\n","        pos_scores += list(prediction[0])\n","        neg_scores += list(prediction[1])\n","    \n","    accuracy = np.sum(np.array(pos_scores) < np.array(neg_scores)) / len(pos_scores)\n","    ap_mean = np.mean(pos_scores)\n","    an_mean = np.mean(neg_scores)\n","    ap_stds = np.std(pos_scores)\n","    an_stds = np.std(neg_scores)\n","    \n","    print(f\"Accuracy on test = {accuracy:.5f}\")\n","    return (accuracy, ap_mean, an_mean, ap_stds, an_stds)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-03-04T15:30:05.206533Z","iopub.status.busy":"2023-03-04T15:30:05.206131Z","iopub.status.idle":"2023-03-04T17:37:31.066939Z","shell.execute_reply":"2023-03-04T17:37:31.066040Z","shell.execute_reply.started":"2023-03-04T15:30:05.206497Z"},"trusted":true},"outputs":[],"source":["import time\n","save_all = False\n","epochs = 30\n","batch_size = 128\n","\n","max_acc = 0\n","train_loss = []\n","test_metrics = []\n","\n","for epoch in range(1, epochs+1):\n","    t = time.time()\n","    \n","    # Training the model on train data\n","    epoch_loss = []\n","    for data in generate_batch_dataset(train, batch_size=batch_size):\n","        loss = siamese_model.train_on_batch(data)\n","        epoch_loss.append(loss)\n","    epoch_loss = sum(epoch_loss)/len(epoch_loss)\n","    train_loss.append(epoch_loss)\n","\n","    print(f\"\\nEPOCH: {epoch} \\t (Epoch done in {int(time.time()-t)} sec)\")\n","    print(f\"Loss on train    = {epoch_loss:.5f}\")\n","    \n","    # Testing the model on test data\n","    metric = test_on_triplets(batch_size=batch_size)\n","    test_metrics.append(metric)\n","    accuracy = metric[0]\n","    "]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2023-03-04T18:08:20.295960Z","iopub.status.busy":"2023-03-04T18:08:20.295598Z","iopub.status.idle":"2023-03-04T18:08:51.846003Z","shell.execute_reply":"2023-03-04T18:08:51.845162Z","shell.execute_reply.started":"2023-03-04T18:08:20.295925Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"]},{"name":"stderr","output_type":"stream","text":["WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"]},{"name":"stdout","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../Model/feature_extractor\\assets\n"]},{"name":"stderr","output_type":"stream","text":["INFO:tensorflow:Assets written to: ../Model/feature_extractor\\assets\n"]},{"name":"stdout","output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," resnet50 (Functional)       (None, 2048)              23587712  \n","                                                                 \n"," dense_2 (Dense)             (None, 256)               524544    \n","                                                                 \n"," batch_normalization_1 (Batc  (None, 256)              1024      \n"," hNormalization)                                                 \n","                                                                 \n"," dense_3 (Dense)             (None, 128)               32896     \n","                                                                 \n"," lambda_1 (Lambda)           (None, 128)               0         \n","                                                                 \n","=================================================================\n","Total params: 24,146,176\n","Trainable params: 9,489,280\n","Non-trainable params: 14,656,896\n","_________________________________________________________________\n"]}],"source":["def extract_encoder(model):\n","    ec = encoder((150, 125, 3))\n","    i=0\n","    for e_layer in model.layers[0].layers[3].layers:\n","        layer_weight = e_layer.get_weights()\n","        ec.layers[i].set_weights(layer_weight)\n","        i+=1\n","    return ec\n","\n","encode = extract_encoder(siamese_model)\n","encode.save(\"../Model/feature_extractor\")\n","encode.summary()"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## References\n","\n","- FaceNet: A Unified Embedding for Face Recognition and Clustering: https://arxiv.org/abs/1503.03832\n","- Image similarity estimation using a Siamese Network with a triplet loss: https://keras.io/examples/vision/siamese_network/\n","- Celebrity Face Recognition: https://www.kaggle.com/ravehgillmore/celebrity-face-recognition/\n","- Face Recognition using Siamese Networks: https://medium.com/wicds/face-recognition-using-siamese-networks-84d6f2e54ea4\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":4}
